#!/bin/bash

###############################################################################
# ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… ìŠ¤í¬ë¦½íŠ¸
# 
# ì‚¬ìš©ë²•:
#   chmod +x scripts/backup-database.sh
#   ./scripts/backup-database.sh
#
# Cron ìë™ ë°±ì—… ì„¤ì • (ë§¤ì¼ ìƒˆë²½ 3ì‹œ):
#   0 3 * * * /path/to/backup-database.sh
###############################################################################

# ì„¤ì •
BACKUP_DIR="/app/backups"
DB_NAME="${DB_NAME:-jakupbanjang}"
DB_USER="${DB_USER:-jakup}"
DB_HOST="${DB_HOST:-localhost}"
DB_PORT="${DB_PORT:-5432}"
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
BACKUP_FILE="$BACKUP_DIR/${DB_NAME}_${TIMESTAMP}.sql"
MAX_BACKUPS=30  # ìµœëŒ€ 30ê°œ ë°±ì—… ìœ ì§€

# ë°±ì—… ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p "$BACKUP_DIR"

echo "ğŸ—„ï¸  ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… ì‹œì‘: $BACKUP_FILE"

# PostgreSQL ë°±ì—…
PGPASSWORD=$DB_PASSWORD pg_dump \
  -h "$DB_HOST" \
  -p "$DB_PORT" \
  -U "$DB_USER" \
  -d "$DB_NAME" \
  -F c \
  -b \
  -v \
  -f "$BACKUP_FILE.custom"

# í…ìŠ¤íŠ¸ í˜•ì‹ë„ í•¨ê»˜ ë°±ì—… (ë³µêµ¬ ì‹œ ìœ ìš©)
PGPASSWORD=$DB_PASSWORD pg_dump \
  -h "$DB_HOST" \
  -p "$DB_PORT" \
  -U "$DB_USER" \
  -d "$DB_NAME" \
  -f "$BACKUP_FILE"

# ë°±ì—… ì••ì¶•
gzip "$BACKUP_FILE"
gzip "$BACKUP_FILE.custom"

# ë°±ì—… ì„±ê³µ ì—¬ë¶€ í™•ì¸
if [ $? -eq 0 ]; then
  echo "âœ… ë°±ì—… ì™„ë£Œ: $BACKUP_FILE.gz"
  
  # ì˜¤ë˜ëœ ë°±ì—… ì‚­ì œ (ìµœê·¼ MAX_BACKUPSê°œë§Œ ìœ ì§€)
  ls -t $BACKUP_DIR/*.gz 2>/dev/null | tail -n +$((MAX_BACKUPS + 1)) | xargs -r rm
  echo "ğŸ§¹ ì˜¤ë˜ëœ ë°±ì—… ì •ë¦¬ ì™„ë£Œ"
  
  # ë°±ì—… íŒŒì¼ ëª©ë¡
  echo "ğŸ“‹ í˜„ì¬ ë°±ì—… íŒŒì¼ ëª©ë¡:"
  ls -lh $BACKUP_DIR/*.gz 2>/dev/null | tail -n 10
else
  echo "âŒ ë°±ì—… ì‹¤íŒ¨"
  exit 1
fi

# ë°±ì—… ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰ í™•ì¸
echo "ğŸ’¾ ë°±ì—… ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰:"
du -sh $BACKUP_DIR

# ì„ íƒì‚¬í•­: S3, Google Cloud Storage ë“± í´ë¼ìš°ë“œ ìŠ¤í† ë¦¬ì§€ì— ì—…ë¡œë“œ
# aws s3 cp "$BACKUP_FILE.gz" s3://your-bucket/backups/
# gsutil cp "$BACKUP_FILE.gz" gs://your-bucket/backups/

echo "âœ¨ ë°±ì—… í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ"

